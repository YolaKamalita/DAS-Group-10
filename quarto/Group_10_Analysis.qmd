---
title: "Analysis of IMDB Rating with GLM"
editor: visual
author: "Group 10"
number-sections: true
format: 
  pdf:
    geometry: "left=2cm, right=2cm, top=2.5cm, bottom=2.5cm"
execute:
  eval: true
  warning: false
  message: false
---

# Introduction {#sec-intro}

Studying the factors that can affect film ratings is an interesting topic to be explored. IMDB dataset containing information about film rating and their properties, such as length or duration, budget, votes, year of release, and genre. There are 1495 films (Film ID) included in the dataset.

In this analysis, the research question is to investigate which properties of films influence IMDB rating, specifically whether they are likely to be greater than 7 or not. The binary rating (i.e., 1 if greater than 7, 0 otherwise) will be the response variables, and the film properties will be the explanatory variables. The GLM (Generalized Linear Model) for binary response variables, in this case Logistic Regression, will be used to investigate the relationship between categorical rating and film properties.

```{r}
#| echo: true
#| warning: false
#| label: tbl-dataset-head
#| tbl-cap: First five entries of the IMDB Dataset

library(tidyverse)
library(gt)

# Read CSV from data dir
df <- read_csv("../data/dataset10.csv")

# Display the first 5 rows
df |> 
  slice_head(n=5) |>
  gt() |>
  cols_label(
    film_id = html("Film ID"),
    year = html("Year"),
    length = html("Length"),
    budget = html("Budget"),
    votes = html("Votes"),
    genre = html("Genre"),
    rating = html("Rating")
  )
```

Description:

-   Film ID: The unique identifier for the film
-   Year: Year of release of the film in cinemas
-   Length: Duration (in minutes)
-   Budget: Budget for the films production (in \$1000000s)
-   Votes: Number of positive votes received by viewers
-   Genre: Genre of the film
-   Rating: IMDB rating from 0-10

# Data Wrangling {#sec-data-wrangling}

```{r}
#| echo: true
#| warning: false

# Import Libraries

library(skimr)
library(knitr)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(stats)
library(jtools)
library(sjPlot)
library(broom)
library(huxtable)
library(lmtest)
library(zoo)
```

```{r}
#| echo: true
#| warning: false
#| label: fig-barplot1
#| fig-cap: The number of NAs for each columns in the dataset.
#| fig-align: center
#| message: false

# Calculate the number of NAs for each column

# Checking NAs
na_sum <- colSums(is.na(df))

# Plotting number of NAs
bp <- barplot(na_sum, 
              main = "Missing Values Count", 
              ylab = "Count",                
              col = "skyblue",              
              names.arg = colnames(df), 
              ylim = c(0, max(na_sum) + 200), # space for labels
              las=1) # rotating x-axis labels
text(x = bp, 
     y = na_sum + 2, 
     labels = na_sum, 
     pos = 3, 
     col = "red")
```

There are 59 from 1945 (10.03%) rows are NA for column length. Moreover, they will be removed as the proportion is pretty small. Another reason is to avoid imputing not accurate information relative to other explanatory variables which might give impact to the statistical analysis result and conclusion.

## Pre-processing Steps

```{r}
#| echo: true
#| warning: false

# Create new columns: rating_higher_than_7
df <- df %>% 
  mutate(rating_higher_than_7 = ifelse(rating <= 7, 0, 1))

# Remove NAs
df <- na.omit(df)
```

The data pre-processing is performed to create new columns to categorize the rating is higher than 7 or not. If yes, it will be marked as 1, and 0 otherwise. Next, the rows which have NAs are being removed from the analysis. Later on, rating_higher_than_7 is going to be the response variable for the following Logistic Regression (GLM) analysis.

# Exploratory Data Analysis {#sec-eda}

## Statistics Descriptive

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-stats
#| tbl-cap: Summary statistics of the IMDB Dataset

# Creating summary statistics

# Convert film_id and rating_higher_than_7 as categorical
IMDB <- df
IMDB <- IMDB %>%
  mutate(film_id = as.character(film_id),
         rating_higher_than_7 = as.character(rating_higher_than_7))

# Summary statistics with adjusted skim()
my_skim <- skim_with(base = sfl(n = length), 
                     numeric = sfl(p0 = NULL, p100 = NULL,hist = NULL))
knit_print(my_skim(IMDB ))
```

Based on the summary tables, there is no duplication for the Film ID, and it means each observation is already unique. Then, the categorical explanatory variables, genre, has seven unique values. Furthermore, the votes has a very wide values by looking at the standard deviation, mean, and median. Year and length are slightly skewed to the left, and then budget and rating are slightly skewed to the right. It can be seen by comparing mean and median position.

## Correlation

```{r}
#| echo: true
#| warning: false
#| label: fig-heatmat1
#| fig-cap: The correlation between numerical variables.
#| fig-align: center
#| message: false

# Calculate the correlation coefficient between numeric variables

# Filter out non-numeric columns
numeric_df <- df[sapply(df, is.numeric)]
numeric_df <- numeric_df[, !names(numeric_df) %in% c("film_id", 
                                                     "rating_higher_than_7")]

# Compute correlation matrix
correlation_matrix <- cor(numeric_df, use = "complete.obs")

# Creating correlation heatmap
corrplot(cor(numeric_df), method = "color", 
         type = "lower", addCoef.col = 'grey')
```

From the @fig-heatmat1, it reveals that rating has a weak negative correlation (-0.47) to length, and has a weak positive correlation (0.25) to budget. Moreover, year and votes show a very weak negative correlation to the rating, -0.01 and -0.04 respectively. It means there is no film properties that can give strong signal (linearly) to the rating. Further investigation will be performed visually using @fig-scatterplot1.

## Scatterplot (Continuous Relationship)

```{r}
#| echo: true
#| warning: false
#| label: fig-scatterplot1
#| fig-cap: The relationship between rating and explanatory variables.
#| fig-align: center
#| message: false

# Creating scatterplot between rating and explanatory variables

# Custom color palette
custom_colors <- c("1" = "lightskyblue", "0" = "dodgerblue4")

# Scatterplot Rating vs. Year with some adjustments
p1 <- ggplot(df, aes(x = year, y = rating, 
                     color = factor(rating_higher_than_7))) +
  geom_point() +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "Orange") +
  scale_color_manual(values = custom_colors) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rating vs Year", x = "Year", y = "Rating")

# Scatterplot Rating vs. Length with some adjustments
p2 <- ggplot(df, aes(x = length, y = rating, 
                     color = factor(rating_higher_than_7))) +
  geom_point() +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "Orange") +
  scale_color_manual(values = custom_colors) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rating vs Length", x = "Length", y = "Rating")

# Scatterplot Rating vs. Budget with some adjustments
p3 <- ggplot(df, aes(x = budget, y = rating, 
                     color = factor(rating_higher_than_7))) +
  geom_point() +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "Orange") +
  scale_color_manual(values = custom_colors) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rating vs Budget", x = "Budget", y = "Rating")

# Scatterplot Rating vs. Votes with some adjustments
p4 <- ggplot(df, aes(x = votes, y = rating, 
                     color = factor(rating_higher_than_7))) +
  geom_point() +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "Orange") +
  scale_color_manual(values = custom_colors) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rating vs Votes", x = "Votes", y = "Rating")

# Plot in Grid
grid.arrange(p1, p2, p3, p4, ncol=2)
```

The red line is the indicator of rating equal to 7. Based on @fig-scatterplot1, most of explanatory variables' values overlap to each other between rating greater and lower than 7. Hypothetically, it might affect the logistic regression performance. However, weak linear relationship to the rating is still noticeable for Budget and Length. Then, the points for year and rating scatterplot are very scattered, indicating very weak relationship between them. Furthermore, there are some outliers for votes showing films which have very high votes (greater than 60k), and interestingly they have ratings lower than 7. These are the Film IDs:

```{r}
#| echo: false
#| warning: false
#| #| label: tbl-outliers
#| tbl-cap: Films having votes greater than 60000

# Filter rows with votes > 60000
df_filter <- df %>% 
  filter(votes > 60000)

# Filter columns to show
df_filter %>% 
  select(film_id, votes, rating)
```

## Boxplot and Barplot (Categorical Relationship)

```{r}
#| echo: true
#| warning: false
#| label: fig-boxplot1
#| fig-cap: The relationship between categorical rating and explanatory variables.
#| fig-align: center
#| fig-width: 7
#| message: false

# Creating boxplot and barplot between rating_higher_than_7 and explanatory variables

# Custom color palette
custom_colors <- c("1" = "lightskyblue", "0" = "dodgerblue4")

# Boxplot Rating > 7 vs. Year with some adjustments
p1 <- ggplot(data = df, 
             mapping = aes(x = factor(rating_higher_than_7), 
                           y = year,
                           fill = factor(rating_higher_than_7))) +
  geom_boxplot() +
  labs(y = "Year", x = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme(legend.position = "none") # remove legend

# Boxplot Rating > 7 vs. Length with some adjustments
p2 <- ggplot(data = df, 
             mapping = aes(x = factor(rating_higher_than_7), 
                           y = length,
                           fill = factor(rating_higher_than_7))) +
  geom_boxplot() +
  labs(y = "Length", x = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme(legend.position = "none") # remove legend

# Boxplot Rating > 7 vs. Budget with some adjustments
p3 <- ggplot(data = df, 
             mapping = aes(x = factor(rating_higher_than_7), 
                           y = budget,
                           fill = factor(rating_higher_than_7))) +
  geom_boxplot() +
  labs(y = "Budget", x = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme(legend.position = "none") # remove legend

# Boxplot Rating > 7 vs. Votes with some adjustments
p4 <- ggplot(data = df, 
             mapping = aes(x = factor(rating_higher_than_7), 
                           y = votes,
                           fill = factor(rating_higher_than_7))) +
  geom_boxplot() +
  labs(y = "Votes", x = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme(legend.position = "none") # remove legend

# Barplot Rating > 7 vs. Genre with some adjustments
p6 <- ggplot(df, aes(x = genre,  y = ..prop.., 
                     group =factor(rating_higher_than_7), 
                     fill = factor(rating_higher_than_7))) +
  geom_bar(position="dodge", stat="count") +
  labs(y = "Proportion", fill = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme_minimal() 

# Plot in Grid
grid.arrange(arrangeGrob(p1, p2, p3, p4, ncol=2), 
             p6, nrow=2, heights = c(2, 1))
```

From the boxplot on the @fig-boxplot1, it is more clear to see that at least Budget and Length can distinguish the rating will be higher or lower than 7. This can be seen by comparing their median lines inside the box. Moreover, there are some points detected as outliers for length and votes.

## Barplot (Genre vs. Rating)

```{r}
#| echo: true
#| warning: false
#| label: fig-barplot2
#| fig-cap: The proportion and average of rating for each genre
#| fig-align: center
#| message: false

# Calculate proportions and average of ratings for each genre categories
ratings_genre <- df %>%
  group_by(genre) %>%
  summarize(
    proportion_higher_than_7 = round(mean(rating_higher_than_7, na.rm = TRUE),3),
    average_rating = round(mean(rating, na.rm = TRUE),2)
    ) %>%
  ungroup() %>% # Grouping is removed so it can be sorted
  arrange(desc(average_rating))

# Create barplot
ggplot(ratings_genre, aes(x = genre)) +
  geom_bar(aes(y = proportion_higher_than_7), 
           stat = "identity", fill = "skyblue", width = 0.5) +
  geom_point(aes(y = average_rating),
            stat="identity",color="red",size=2)+
  labs(x = "Genre", y = "Proportions of Rating > 7",
       title = "Rating vs. Genre") +
  scale_y_continuous(sec.axis=sec_axis(~.,name="Average of Rating"),
                     limits = c(0,9)) + # creating second y-axis
  geom_text(aes(y = proportion_higher_than_7,
                label = round(proportion_higher_than_7, 2)), 
            vjust = -0.5, color = "black", size = 3.5) +
  geom_text(aes(y = average_rating,label = average_rating), 
            vjust = -0.5, color = "black", size = 3.5)
```

@fig-barplot2 shows that Action and Drama have a low proportion of having rating greater than 7, and their average of ratings are 4.63 and 4.14 respectively. The Short genre becomes the highest for both proportion and average of rating. Visually, genre is helpful to distinguish whether the rating will be high or low.

# Statistical Analysis (GLM) {#sec-glm-analysis}

## Model Fitting

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-glm
#| tbl-cap: Hypothesis Testing and Goodness of fit.

# Fitting the model
model <- glm(rating_higher_than_7 ~ length + budget + genre, 
             data = df, 
             family = binomial(link = "logit"))

# Display the model summary (log-odds)
model %>%
  summ()
```

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-glm2
#| tbl-cap: Confidence Intervals for Hypothesis Testing.

# Display CI for the log-odds
confint(model) %>%
  kable()
```

Based on the result, the log-odds coefficients for budget is positive indicating the higher their values then the rating higher than 7 will be more likely. Furthermore, the log-odds coefficients for length is negative, and it indicates that the lower the values, the rating to be higher than 7 is more likely. These coefficients are statistically significant because the P-values are lower than 0.05 and practically significant because Confidence Intervals (CI) do not contain 0. There are some coefficients which are not statistically significant, such as genreAnimation and genreRomance.

```{r}
#| echo: false
#| warning: false

# Display Deviance
print(paste("Residual Deviance:", summary(model)$deviance))
print(paste("Null Deviance:", summary(model)$null.deviance))
```

Next, hypothesis testing using Deviance can be used to compare nested models $M_0$ and $M_1$. Null deviance $D_0$ is the deviance from model with intercept only and $D_1$ is the deviance from model of interest (intercept + predictors). In this case, $H_0$ is $M_0$ is more likely ( $\beta$ = $\beta_0$ ). Since, $D_0$ - $D_1$ = 1128.12 \> $\chi^2(0.95;8)$ = 15.507, $H_0$ is rejected. So, retaining length, budget, and budget is worthwhile.

Furthermore, if the model is a good of fit, the residual deviance $D_1$ = 726.85 should approximately follow $\chi^2(0.95;n-p)$ = $\chi^2(0.95;1427)$ = 1515.995. Then, since 726.85 \< 1515.995, there is no evidence of lack of fit and the number of samples are reasonably large.

One caveat of using this model is genreAnimation and genreRomance are not statistically significant. However, if genre is being removed, AIC will increase drastically to 1298. It is reasonable to keep genre as there is no evidence of lack of fit.

```{r}
#| echo: true
#| warning: false
#| label: fig-oddratios
#| fig-cap: Red dots implying negative relationship and blue dots implying positive relationship. Significant coefficients are marked with stars.
#| fig-align: center
#| message: false
#| fig-width: 8

# Plot Odds Ratios for each parameters
plot_model(model, show.values=TRUE)
```

According to @fig-oddratios, as length and budget increase, the odds of having rating greater 7 will be decreasing (multiply by 0.94) and increasing (multiply by 1.78) respectively. In this analysis, the baseline for Genre is Action. For Comedy, Documentary, and Short films, the odds ratios have values much higher than 1. As an example, Comedy's odds of having rating higher than 7 is 24.22 times those of Action films.

Interestingly, the Animation's odds is 0.49 times to Action's odds, and this is not align with the fact that Animation's proportion (of having rating higher than 7) is bigger than Action. Moreover, this is not statistically significant.

```{r}
#| echo: true
#| warning: false
#| label: fig-predprob1
#| fig-cap: Predicted Probabilities of rating higher than 7 for budget and genre.
#| fig-align: center
#| message: false

# Plot predicted probabilities of having rating higher than 7
plot_model(model,type="pred",terms=c("length","genre"))
```

```{r}
#| echo: true
#| warning: false
#| label: fig-predprob2
#| fig-cap: Predicted Probabilities of rating higher than 7 for length and genre.
#| fig-align: center
#| message: false

# Plot predicted probabilities of having rating higher than 7
plot_model(model,type="pred",terms=c("budget","genre"))
```

Other than Romance genre, the probabilities of having rating higher than 7 decreasing by length and increasing by budget. It can also be seen from odds sign as well in @fig-oddratios. Moreover, we can also compare to @fig-barplot2 that Romance (0%), Drama (5%), and Action (16%) are the lowest in terms of proportion of having rating greater than 7, and this is align with their predicted probabilities. However, this is not case for Animation predicted probabilities as GenreAnimation coefficient is not so reliable, the prediction probabilities can be a bit problematic. For Romance genre, it will be always predicted to have rating lower than and equal to 7.

## Model Selection

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-comparison-glm
#| tbl-cap: Hypothesis Testing and Goodness of fit.

# Comparing models with different explanatory variables

model_2 <- glm(rating_higher_than_7 ~ year + length + budget + votes + genre, 
               data = df, 
               family = binomial(link = "logit"))

suppressWarnings(export_summs(model, model_2,
                error_format = "[{conf.low}, {conf.high}]"))
```

After doing some investigations, the model with year and votes has slightly lower AIC, but higher BIC. Moreover, the year coefficient is not statistically and practically significant by looking at P-value and CI contains 0. Then, the votes coefficient is not practically significant because of having CI is very close to 0.

Removing year and votes will not significantly reduce AIC, but improving BIC quite significantly. BIC favors simpler model. Other than that, from @fig-heatmat1, we know that correlation for year and votes to rating is very weak. Hence, Model 1 is selected to be the final model.

\clearpage

## Sanity Checking: Linear Regression

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-comparison-lm
#| tbl-cap: Hypothesis Testing and Goodness of fit.

# Fitting the model_3 (rating > 7) and model_4 (rating <= 7)

df_higher <- df[df$rating_higher_than_7 == 1, ]
df_lower <- df[df$rating_higher_than_7 == 0, ]

model_3 <- lm(rating ~ length + budget + genre,
              data = df_lower)
model_4 <- lm(rating ~ length + budget +  genre, 
              data = df_higher)

suppressWarnings(export_summs(model_3, model_4,
                error_format = "[{conf.low}, {conf.high}]"))
```

In this part, the one in the left (Model 3) is model which has observations with rating \<= 7 and the one on the right (Model 4) having observation with rating \> 7. They are fitted separately in order to analyze the effects of variables separately on high-scoring and low-scoring movies. In model 4, when rating is higher than 7, budget has a higher impact on rating than lenght. As the budget gets higher then rating is also getting higher, but we see the opposite for the length. For Model 3, the rating gets higher as the budget and length getting higher. However, for both models, the coefficients are not statistically and practically significant.

\clearpage

# Conclusion {#sec-conclusion}

-   The model which has budget, length, and genre as the predictors are chosen to be the best model. The AIC is slightly lower than model which also has year and votes as the predictors, but BIC is higher. In this case, simpler model is chosen.

-   The caveat from this model that it has coefficients which are statistically significant (genreAnimation and genreRomance). However, if genre is being removed, AIC will increase significantly. It is better to have genre as predictors as well. The hypothesis on Deviance also shows no evidence for lack of fit.

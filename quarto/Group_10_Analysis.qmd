---
title: "Analysis of IMDB Rating with GLM"
editor: visual
author: "Group 10"
number-sections: true
format: 
  pdf:
    geometry: "left=2cm, right=2cm, top=2.5cm, bottom=2.5cm"
execute:
  eval: true
  warning: false
  message: false
---

# Introduction {#sec-intro}

Studying the factors that can affect film ratings is an interesting topic to be explored. IMDB dataset containing information about film rating and their properties, such as length or duration, budget, votes, year of release, and genre. There are 1495 films (Film ID) included in the dataset.

In this analysis, the research question is to investigate which properties of films influence whether IMDB rating exceeding 7 or not. The binary rating (i.e., 1 if greater than 7 and 0 otherwise) will be the response variables, and the film properties will be the explanatory variables. The GLM (Generalized Linear Model) for binary response variables, Logistic Regression, will be used to investigate the relationship between binary rating and film properties.

```{r}
#| echo: true
#| warning: false
#| label: tbl-dataset-head
#| tbl-cap: First five entries of the IMDB Dataset.

library(tidyverse)
library(gt)

# Read CSV from data dir
df <- read_csv("../data/dataset10.csv")

# Display the first 5 rows
df |> 
  slice_head(n=5) |>
  gt() |>
  cols_label(
    film_id = html("Film ID"),
    year = html("Year"),
    length = html("Length"),
    budget = html("Budget"),
    votes = html("Votes"),
    genre = html("Genre"),
    rating = html("Rating")
  )
```

Description:

-   Film ID: The unique identifier for the film.
-   Year: Year of release of the film in cinemas.
-   Length: Duration (in minutes).
-   Budget: Budget for the films production (in \$1000000).
-   Votes: Number of positive votes received by viewers.
-   Genre: Genre of the film.
-   Rating: IMDB rating from 0-10.

# Data Wrangling {#sec-data-wrangling}

```{r}
#| echo: true
#| warning: false

# Import Libraries

library(skimr)
library(knitr)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(stats)
library(jtools)
library(sjPlot)
library(broom)
library(huxtable)
library(lmtest)
library(zoo)
```

```{r}
#| echo: true
#| warning: false
#| label: fig-barplot1
#| fig-cap: The number of NAs for each column in the dataset.
#| fig-align: center
#| message: false

# Calculate the number of NAs for each column

# Checking NAs
na_sum <- colSums(is.na(df))

# Plotting number of NAs
bp <- barplot(na_sum, 
              main = "Missing Values Count", 
              ylab = "Count",                
              col = "skyblue",              
              names.arg = colnames(df), 
              ylim = c(0, max(na_sum) + 200), # space for labels
              las=1) # rotating x-axis labels
text(x = bp, 
     y = na_sum + 2, 
     labels = na_sum, 
     pos = 3, 
     col = "red")
```

In the column length, there are 59 from 1945 (10.03%) rows containing NA values. Moreover, they will be removed as the proportion is pretty small. Another reason is to avoid imputing inaccurate information relative to other explanatory variables which might give impact to the statistical analysis result and conclusion.

## Preprocessing Steps

```{r}
#| echo: true
#| warning: false

# Create new columns: rating_higher_than_7
df <- df %>% 
  mutate(rating_higher_than_7 = ifelse(rating <= 7, 0, 1))

# Remove NAs
df <- na.omit(df)
```

The data preprocessing is performed to create new columns to categorize the rating is higher than 7 or not. If yes, it will be marked as 1, and 0 otherwise. Next, the rows which have NAs are being removed from the analysis. Later on, rating_higher_than_7 is going to be the response variable for the following Logistic Regression (GLM) analysis.

# Exploratory Data Analysis {#sec-eda}

## Statistics Descriptive

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-stats
#| tbl-cap: Summary statistics of the IMDB Dataset.

# Creating summary statistics

# Convert film_id and rating_higher_than_7 as categorical
IMDB <- df
IMDB <- IMDB %>%
  mutate(film_id = as.character(film_id),
         rating_higher_than_7 = as.character(rating_higher_than_7))

# Summary statistics with adjusted skim()
my_skim <- skim_with(base = sfl(n = length), 
                     numeric = sfl(p0 = NULL, p100 = NULL,hist = NULL))
knit_print(my_skim(IMDB ))
```

Based on the summary tables @tbl-summary-stats, there is no duplication for the Film ID, and it means each observation is already unique. Then, the categorical explanatory variables, genre, has seven unique values. Furthermore, the votes has a very wide values by looking at the standard deviation, mean, and median. Year and length are slightly skewed to the left, and then budget and rating are slightly skewed to the right. It can be seen by comparing mean and median position.

\clearpage

## Correlation

```{r}
#| echo: true
#| warning: false
#| label: fig-heatmat1
#| fig-cap: The correlation between numerical variables.
#| fig-align: center
#| message: false

# Calculate the correlation coefficient between numeric variables

# Filter out non-numeric columns
numeric_df <- df[sapply(df, is.numeric)]
numeric_df <- numeric_df[, !names(numeric_df) %in% c("film_id", 
                                                     "rating_higher_than_7")]

# Compute correlation matrix
correlation_matrix <- cor(numeric_df, use = "complete.obs")

# Creating correlation heatmap
corrplot(cor(numeric_df), method = "color", 
         type = "lower", addCoef.col = 'grey')
```

From the @fig-heatmat1, it reveals that rating has a weak negative correlation (-0.47) to length, and has a weak positive correlation (0.25) to budget. Moreover, year and votes show a very weak negative correlation to the rating, -0.01 and -0.04 respectively. It means there is no film properties that can give strong signal (linearly) to the rating. Further investigation will be performed visually using @fig-scatterplot1.

## Scatterplot (Continuous Relationship)

```{r}
#| echo: true
#| warning: false
#| label: fig-scatterplot1
#| fig-cap: The relationship between rating and continuous explanatory variables.
#| fig-align: center
#| message: false

# Creating scatterplot between rating and explanatory variables

# Custom color palette
custom_colors <- c("1" = "lightskyblue", "0" = "dodgerblue4")

# Scatterplot Rating vs. Year with some adjustments
p1 <- ggplot(df, aes(x = year, y = rating, 
                     color = factor(rating_higher_than_7))) +
  geom_point() +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "Orange") +
  scale_color_manual(values = custom_colors) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rating vs Year", x = "Year", y = "Rating")

# Scatterplot Rating vs. Length with some adjustments
p2 <- ggplot(df, aes(x = length, y = rating, 
                     color = factor(rating_higher_than_7))) +
  geom_point() +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "Orange") +
  scale_color_manual(values = custom_colors) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rating vs Length", x = "Length", y = "Rating")

# Scatterplot Rating vs. Budget with some adjustments
p3 <- ggplot(df, aes(x = budget, y = rating, 
                     color = factor(rating_higher_than_7))) +
  geom_point() +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "Orange") +
  scale_color_manual(values = custom_colors) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rating vs Budget", x = "Budget", y = "Rating")

# Scatterplot Rating vs. Votes with some adjustments
p4 <- ggplot(df, aes(x = votes, y = rating, 
                     color = factor(rating_higher_than_7))) +
  geom_point() +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red") +
  geom_smooth(method = "lm", se = FALSE, color = "Orange") +
  scale_color_manual(values = custom_colors) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rating vs Votes", x = "Votes", y = "Rating")

# Plot in Grid
grid.arrange(p1, p2, p3, p4, ncol=2)
```

The red line is the indicator of rating equal to 7. Based on @fig-scatterplot1, most of explanatory variables' values overlap to each other between rating greater and lower than 7. Hypothetically, it might affect the logistic regression performance. However, weak linear relationship to the rating is still noticeable for Budget and Length. Then, the points for year and rating scatterplot are very scattered, indicating very weak relationship between them. Furthermore, there are some outliers for votes showing films which have very high votes (greater than 60k), and interestingly they have ratings lower than 7. These are the Film IDs:

```{r}
#| echo: false
#| warning: false
#| #| label: tbl-outliers
#| tbl-cap: Films having votes greater than 60000.

# Filter rows with votes > 60000
df_filter <- df %>% 
  filter(votes > 60000)

# Filter columns to show
df_filter %>% 
  select(film_id, votes, rating) %>%
  kable()
```

## Boxplot and Barplot (Categorical Relationship)

```{r}
#| echo: true
#| warning: false
#| label: fig-boxplot1
#| fig-cap: The relationship between binary rating and explanatory variables.
#| fig-align: center
#| fig-width: 7
#| message: false

# Creating boxplot and barplot between rating_higher_than_7 and explanatory variables

# Custom color palette
custom_colors <- c("1" = "lightskyblue", "0" = "dodgerblue4")

# Boxplot Rating > 7 vs. Year with some adjustments
p1 <- ggplot(data = df, 
             mapping = aes(x = factor(rating_higher_than_7), 
                           y = year,
                           fill = factor(rating_higher_than_7))) +
  geom_boxplot() +
  labs(y = "Year", x = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme(legend.position = "none") # remove legend

# Boxplot Rating > 7 vs. Length with some adjustments
p2 <- ggplot(data = df, 
             mapping = aes(x = factor(rating_higher_than_7), 
                           y = length,
                           fill = factor(rating_higher_than_7))) +
  geom_boxplot() +
  labs(y = "Length", x = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme(legend.position = "none") # remove legend

# Boxplot Rating > 7 vs. Budget with some adjustments
p3 <- ggplot(data = df, 
             mapping = aes(x = factor(rating_higher_than_7), 
                           y = budget,
                           fill = factor(rating_higher_than_7))) +
  geom_boxplot() +
  labs(y = "Budget", x = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme(legend.position = "none") # remove legend

# Boxplot Rating > 7 vs. Votes with some adjustments
p4 <- ggplot(data = df, 
             mapping = aes(x = factor(rating_higher_than_7), 
                           y = votes,
                           fill = factor(rating_higher_than_7))) +
  geom_boxplot() +
  labs(y = "Votes", x = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme(legend.position = "none") # remove legend

# Barplot Rating > 7 vs. Genre with some adjustments
p6 <- ggplot(df, aes(x = genre,  y = ..prop.., 
                     group =factor(rating_higher_than_7), 
                     fill = factor(rating_higher_than_7))) +
  geom_bar(position="dodge", stat="count") +
  labs(y = "Proportion", fill = "Rating > 7") +
  scale_fill_manual(values = custom_colors) +
  theme_minimal() 

# Plot in Grid
grid.arrange(arrangeGrob(p1, p2, p3, p4, ncol=2), 
             p6, nrow=2, heights = c(2, 1))
```

From the boxplot on the @fig-boxplot1, it is more clear to see that Budget and Length is more helpful to distinguish the rating will be higher or lower than 7. This can be seen by comparing their median lines inside the box. Moreover, there are a lot of points detected as outliers for length and votes.

## Barplot (Genre vs. Rating)

```{r}
#| echo: true
#| warning: false
#| label: fig-barplot2
#| fig-cap: The proportion and average of rating for each genre.
#| fig-align: center
#| message: false

# Calculate proportions and average of ratings for each genre categories
ratings_genre <- df %>%
  group_by(genre) %>%
  summarize(
    proportion_higher_than_7 = round(mean(rating_higher_than_7, na.rm = TRUE),3),
    average_rating = round(mean(rating, na.rm = TRUE),2)
    ) %>%
  ungroup() %>% # Grouping is removed so it can be sorted
  arrange(desc(average_rating))

# Create barplot
ggplot(ratings_genre, aes(x = genre)) +
  geom_bar(aes(y = proportion_higher_than_7), 
           stat = "identity", fill = "skyblue", width = 0.5) +
  geom_point(aes(y = average_rating),
            stat="identity",color="red",size=2)+
  labs(x = "Genre", y = "Proportions of Rating > 7",
       title = "Rating vs. Genre") +
  scale_y_continuous(sec.axis=sec_axis(~.,name="Average of Rating"),
                     limits = c(0,9)) + # creating second y-axis
  geom_text(aes(y = proportion_higher_than_7,
                label = round(proportion_higher_than_7, 2)), 
            vjust = -0.5, color = "black", size = 3.5) +
  geom_text(aes(y = average_rating,label = average_rating), 
            vjust = -0.5, color = "black", size = 3.5)
```

@fig-barplot2 shows that Action (16%) and Drama (5%) have a low proportion of having rating greater than 7, and their average of ratings are 4.63 and 4.14 respectively. The Short genre becomes the highest for both proportion (97%) and average (7.98) of rating. Visually, genre is helpful to distinguish whether the rating will be high or low.

# Statistical Analysis (GLM) {#sec-glm-analysis}

## Model Fitting and Selection

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-comparison-glm
#| tbl-cap: Hypothesis Testing and Goodness of fit. The one on the left-hand side is the model without the year and votes explanatory variables.

# Comparing models with different explanatory variables

model <- glm(rating_higher_than_7 ~ length + budget + genre, 
             data = df, 
             family = binomial(link = "logit"))
model_2 <- glm(rating_higher_than_7 ~ year + length + budget + votes + genre, 
               data = df, 
               family = binomial(link = "logit"))

suppressWarnings(export_summs(model, model_2,
                error_format = "[{conf.low}, {conf.high}]"))
```

Following a comprehensive investigations in @tbl-summary-comparison-glm, it is observed that the model incorporating the variables of year and votes (Model 2) has a slightly lower Akaike Information Criterion (AIC), but a noticeable increase in the Bayesian Information Criterion (BIC). Moreover, the coefficient associated with the year variable is not statistically and practically significant by looking at P-value higher than 5% Alpha and 95% CI contains 0. Similarly, the votes coefficient is not practically significant because of having 95% CI is very close to 0. Additionally, by looking at @fig-heatmat1 reveals a very weak correlation from the year and votes to the rating variables. Hence, Model 1 is selected to be the better model. Removing year and votes resulting in a minor increment in AIC but significantly reduce the BIC. In this case, BIC favors simpler model.

Furthermore, one caveat of using this model is genreAnimation and genreRomance are not statistically significant. However, if genre is being removed, AIC will increase drastically to 1298. Please refer to the @sec-appendix. For now, it is reasonable to keep genre as one of the explanatory variables. Goodness of fit test will be performed in the next step.

\clearpage

## Examination of the Final Model

### Hypothesis Testing and Goodness of fit

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-glm
#| tbl-cap: Hypothesis Testing and Goodness of fit.

# Display the model summary (log-odds)
model %>%
  summ()
```

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-glm2
#| tbl-cap: Confidence Intervals for Hypothesis Testing.

# Display CI for the log-odds
confint(model) %>%
  kable()
```

The Logistic Regression formula can be written as:

$$
log(\frac{P_i}{1-P_i}) = \alpha + \beta_{budget} \cdot {budget}_i + \beta_{length} \cdot {length}_i + \beta_{\text{Animation}} \cdot \mathbb{I}_{\text{Animation}}(i) + \beta_{\text{Comedy}} \cdot \mathbb{I}_{\text{Comedy}}(i) +
$$

$$
\beta_{\text{Documentary}} \cdot \mathbb{I}_{\text{Documentary}}(i) + \beta_{\text{Drama}} \cdot \mathbb{I}_{\text{Drama}}(i) + \beta_{\text{Romance}} \cdot \mathbb{I}_{\text{Romance}}(i) + \beta_{\text{Short}} \cdot \mathbb{I}_{\text{Short}}(i)
$$

where $\beta_{\text{Genre}} \cdot \mathbb{I}_{\text{Genre}}$ is an indicator function such that

$$
\mathbb{I}_{\mbox{Genre}}(x)=\left\{
                \begin{array}{ll}
                  1 ~~~ \mbox{xth observation is part of the genre},\\
                  0 ~~~ \mbox{Otherwise}.\\
                \end{array}
              \right.
$$

Based on the result @tbl-summary-glm, the log-odds coefficients associated with the budget variable is positive. This suggests that as the budget values increase, the likelihood of the rating greater than 7 also increases. Furthermore, the log-odds coefficients for length is negative, and it indicates that the lower the values, the rating to be higher than 7 is more likely. @tbl-summary-glm2 shows that these two coefficients are statistically significant because the P-values are lower than 0.05 and practically significant because Confidence Intervals (CI) do not contain 0. There are two coefficients which are not statistically significant, genreAnimation and genreRomance.

```{r}
#| echo: true
#| warning: true

# Hosmer-Lemeshow goodness of fit test

source(url("http://www.chrisbilder.com/categorical/Chapter5/AllGOFTests.R"))

HLTest(model, g=6)
```

Next, Hosmer-Lemeshow goodness of fit test is performed. Large P-values indicates no evidence for lack of fit. However, some expected counts are less than 5, so the test might not be very reliable. As there is no evidence of lack of fit, explanatory variables are worth to be retained. Moreover, checking residuals for model diagnostic is not informative for binary response variable.

### Odds-ratios

```{r}
#| echo: true
#| warning: false
#| label: fig-oddratios
#| fig-cap: Red dots implying negative relationship, while blue dots suggest positive relationship. Significant coefficients are marked with stars.
#| fig-align: center
#| message: false
#| fig-width: 8

# Plot Odds Ratios for each parameters
plot_model(model, show.values=TRUE)
```

According to @fig-oddratios, as length and budget increase, the odds of having rating greater 7 will be decreasing (multiply by 0.94) and increasing (multiply by 1.78) respectively. In this analysis, the baseline for Genre is Action. For Comedy, Documentary, and Short films, the odds ratios have values significantly higher than 1. For instance, Comedy's odds of having rating higher than 7 is 24.22 times those of Action films.

Interestingly, the Animation's odds is 0.49 times to Action's odds, and this is not align with the fact that Animation's proportion (of having rating higher than 7) is bigger than Action. Moreover, we notice that Animation has a mean of length 19.92 min, which is lower than the overall mean, 82.29 min from @tbl-summary-stats. This is also already align with the negative correlation between length and rating which can be seen from @fig-heatmat1. One hypothesis, compared to other genres, Animation is very skewed in terms of length values, and its IQR is 15 times smaller than SD - @tbl-summary-genre-length. However, Animation's odds is not statistically significant.

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-genre-length
#| tbl-cap: Summary statistics of length for each genre.

df |>
   summarize('Mean' = mean(length),
             'Median' = median(length),
             'St.Dev' = sd(length),
             'IQR' = quantile(length,0.75)-quantile(length,0.25),
             'Sample_size' = n(),
.by = genre) |>
 gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )
```

### Predicted Probabilities

```{r}
#| echo: true
#| warning: false
#| label: fig-predprob1
#| fig-cap: Predicted probabilities of rating higher than 7 for budget and genre.
#| fig-align: center
#| message: false

# Plot predicted probabilities of having rating higher than 7
plot_model(model,type="pred",terms=c("length","genre"))
```

```{r}
#| echo: true
#| warning: false
#| label: fig-predprob2
#| fig-cap: Predicted probabilities of rating higher than 7 for length and genre.
#| fig-align: center
#| message: false

# Plot predicted probabilities of having rating higher than 7
plot_model(model,type="pred",terms=c("budget","genre"))
```

Other than Romance genre, the probabilities of having rating higher than 7 decreasing by length and increasing by budget. It can also be seen from odds sign as well in @fig-oddratios. Moreover, we can also compare to @fig-barplot2 that Romance (0%), Drama (5%), and Action (16%) are the lowest in terms of proportion of having rating greater than 7, and this is align with their predicted probabilities. However, this is not the case for Animation predicted probabilities. For Romance, it will be always predicted to have rating lower than and equal to 7.

## Sanity Checking: Linear Regression

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-comparison-lm
#| tbl-cap: Hypothesis Testing and Goodness of fit. The one on the left is model which has observations with rating <= 7 and the one on the right having observation with rating > 7.

# Fitting the model_3 (rating > 7) and model_4 (rating <= 7)

df_higher <- df[df$rating_higher_than_7 == 1, ]
df_lower <- df[df$rating_higher_than_7 == 0, ]

model_3 <- lm(rating ~ length + budget + genre,
              data = df_lower)
model_4 <- lm(rating ~ length + budget +  genre, 
              data = df_higher)

suppressWarnings(export_summs(model_3, model_4,
                error_format = "[{conf.low}, {conf.high}]"))
```

In this part, the one on the left is model which has observations with rating \<= 7 and the one on the right having observation with rating \> 7. They are fitted separately in order to analyze the effects of variables separately on high-scoring and low-scoring movies. In model 2, when rating is higher than 7, budget has a slightly higher impact on rating than length by looking at the effect size or the magnitude of the coefficients. However, both coefficients are very close to 0, so they are not practically significant. As the budget gets higher then rating is also getting higher, but we see the opposite for the length. For Model 1, the rating gets higher as the budget and length getting higher. However, for both models, the coefficients are not statistically and practically significant.

\clearpage

# Conclusion {#sec-conclusion}

The model which has budget, length, and genre as the predictors is chosen to be the best model. The AIC is slightly lower than model which also has year and votes as the predictors, but BIC is noticeably higher. In this case, simpler model is chosen.

The caveat from this model that it has coefficients which are not statistically significant (genreAnimation and genreRomance). However, if genre is being removed, AIC will increase significantly. It is better to incorporate genre as predictors. The hypothesis on Hosmer-Lemeshow also shows no evidence for lack of fit.

In summary, answering the research question, budget and length have significant relationship to binary rating, whether greater than 7 or not. For Genre, two of them are not significant.

# Appendix {#sec-appendix}

```{r}
#| echo: true
#| warning: false
#| label: tbl-summary-glm3
#| tbl-cap: Hypothesis Testing and Goodness of fit. Model without year, votes, and genre.

# Comparing models with different explanatory variables

model_6 <- glm(rating_higher_than_7 ~ length + budget, 
               data = df, 
               family = binomial(link = "logit"))

# Display the model summary (log-odds)
model_6 %>%
  summ(model.info = FALSE)
```
